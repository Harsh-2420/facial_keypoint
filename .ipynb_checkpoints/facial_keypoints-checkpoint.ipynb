{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, Activation, Convolution2D, MaxPooling2D, BatchNormalization, MaxPool2D, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/harshjhunjhunwala/Desktop/github_datasets/facial-keypoints-detection/training.csv\")\n",
    "test_df =  pd.read_csv(\"/Users/harshjhunjhunwala/Desktop/github_datasets/facial-keypoints-detection/test.csv\")\n",
    "lookid_df = pd.read_csv(\"/Users/harshjhunjhunwala/Desktop/github_datasets/facial-keypoints-detection/IdLookupTable.csv\")\n",
    "# train_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_eye_center_x             True\n",
       "left_eye_center_y             True\n",
       "right_eye_center_x            True\n",
       "right_eye_center_y            True\n",
       "left_eye_inner_corner_x       True\n",
       "left_eye_inner_corner_y       True\n",
       "left_eye_outer_corner_x       True\n",
       "left_eye_outer_corner_y       True\n",
       "right_eye_inner_corner_x      True\n",
       "right_eye_inner_corner_y      True\n",
       "right_eye_outer_corner_x      True\n",
       "right_eye_outer_corner_y      True\n",
       "left_eyebrow_inner_end_x      True\n",
       "left_eyebrow_inner_end_y      True\n",
       "left_eyebrow_outer_end_x      True\n",
       "left_eyebrow_outer_end_y      True\n",
       "right_eyebrow_inner_end_x     True\n",
       "right_eyebrow_inner_end_y     True\n",
       "right_eyebrow_outer_end_x     True\n",
       "right_eyebrow_outer_end_y     True\n",
       "nose_tip_x                   False\n",
       "nose_tip_y                   False\n",
       "mouth_left_corner_x           True\n",
       "mouth_left_corner_y           True\n",
       "mouth_right_corner_x          True\n",
       "mouth_right_corner_y          True\n",
       "mouth_center_top_lip_x        True\n",
       "mouth_center_top_lip_y        True\n",
       "mouth_center_bottom_lip_x     True\n",
       "mouth_center_bottom_lip_y     True\n",
       "Image                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.fillna(method='ffill', inplace=True)\n",
    "train_df.isnull().any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the str image values into list by splitting on spaces:\n",
    "\n",
    "img = []\n",
    "for i in range(len(train_df)):\n",
    "    image = train_df['Image'][i].split(\" \")\n",
    "    image = ['0' if x == '' else x for x in image]\n",
    "    img.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = np.array(img, dtype='float')\n",
    "# plt.imshow(img_list[0].reshape(96, 96))\n",
    "# plt.show()\n",
    "X_train = img_list.reshape(-1, 96, 96, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.drop('Image', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(7049):\n",
    "    y = train_data.iloc[i,:]\n",
    "    y_train.append(y)\n",
    "\n",
    "y_train = np.array(y_train, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "        \n",
    "#convolution 1st time\n",
    "model.add(Conv2D(32, (3,3), activation='relu',input_shape=(96,96,1)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    " #convolution 2nd time\n",
    "model.add(Conv2D(32, (3,3),activation='relu',input_shape=(96,96,1)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    " #convolution 2nd time\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation=tf.nn.relu,input_shape=(96,96,1)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "#input layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=526,activation='relu'))\n",
    "model.add(Dense(units=526,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# number of keypoint\n",
    "model.add(Dense(units=30,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5639 samples, validate on 1410 samples\n",
      "Epoch 1/4\n",
      "5639/5639 [==============================] - 43s 8ms/step - loss: 267.0264 - mae: 12.8164 - val_loss: 101.1267 - val_mae: 7.3709\n",
      "Epoch 2/4\n",
      "5639/5639 [==============================] - 46s 8ms/step - loss: 157.1068 - mae: 9.7962 - val_loss: 84.5980 - val_mae: 6.8038\n",
      "Epoch 3/4\n",
      "5639/5639 [==============================] - 46s 8ms/step - loss: 129.9526 - mae: 8.8612 - val_loss: 79.7124 - val_mae: 6.4503\n",
      "Epoch 4/4\n",
      "5639/5639 [==============================] - 46s 8ms/step - loss: 111.8176 - mae: 8.1958 - val_loss: 76.1144 - val_mae: 6.2978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c1bdcf10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"mae\"])\n",
    "model.fit(X_train, y_train, epochs=4, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
